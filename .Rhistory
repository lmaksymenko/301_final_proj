'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
summary(linmod), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
summary(linmod), '\n',
#strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
#strrep('-', 80), '\n',
summary(linmod), '\n',
#strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
#summary(linmod), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
summary(linmod), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
unlist(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
#unlist(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
unlist(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
paste(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
summary(linmod)
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
capture.output(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
print('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
capture.output(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
message('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
capture.output(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
capture.output(summary(linmod)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
summary(linmod)
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
capture.output(summary(linmod), split = TRUE), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
capture.output(summary(linmod), split = TRUE)
cat(capture.output(summary(linmod), split = TRUE))
print(capture.output(summary(linmod), split = TRUE))
print(capture.output(summary(linmod), split = TRUE))
capture.output(summary(linmod))
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
print(capture.output(summary(linmod), split = TRUE)), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
capture.output(summary(linmod))
print(capture.output(summary(linmod)))
print(capture.output(summary(linmod)))
cat(capture.output(summary(linmod)))
cat(capture.output(summary(linmod)), fill = TRUE)
capture.output(summary(linmod)
capture.output(summary(linmod))
capture.output(summary(linmod))
cat(capture.output(summary(linmod)), fill = TRUE)
paste(capture.output(summary(linmod)))
cat(paste(capture.output(summary(linmod)))
cat(paste(capture.output(summary(linmod))))
cat( paste(capture.output(summary(linmod))) )
cat( print(capture.output(summary(linmod))) )
cat( print(capture.output(summary(linmod))), fill = TRUE )
summary(linmod)
capture.output(summary(linmod))
lapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )
cat(lapply(capture.output(summary(linmod)), function(x) paste(x, '\n') ))
cat(unlist(lapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )))
cat((sapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )))
cat((sapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )))
cat(sapply(capture.output(summary(linmod)), function(x) paste(x, '\n') ))
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
cat(sapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
cat(sapply(capture.output(summary(linmod)), function(x) paste(x, '\n') )), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
sapply(capture.output(summary(linmod)), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80), '\n',
sapply(capture.output(summary(linmod)), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(summary(linmod)), function(x) paste(x, '\n')), '\n',
strrep('-', 80),
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
cat('LINEAR MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(summary(linmod)), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', linmod.train.mse, '\n',
'Test MSE: ', linmod.test.mse, '\n')
rf.reg = randomForest(spy_var~.,data=data, subset = trainsub,
ntree=100,mtry=3,importance=TRUE, na.action = na.roughfix) #mtry is number of variables
rf.reg #Gives both the number of variables at each split but also provides out-of-bag estimate of error rate
summary(rf.reg) #Gives both the number of variables at each split but also provides out-of-bag estimate of error rate
rf.reg = randomForest(spy_var~.,data=data, subset = trainsub,
ntree=100,mtry=3,importance=TRUE, na.action = na.roughfix) #mtry is number of variables
rf.reg #Gives both the number of variables at each split but also provides out-of-bag estimate of error rate
rf.reg = randomForest(spy_var~.,data=data, subset = trainsub,
ntree=100,mtry=3,importance=TRUE, na.action = na.roughfix) #mtry is number of variables
rf.reg #Gives both the number of variables at each split but also provides out-of-bag estimate of error rate
rf.train.mse = mean((data$spy_var[trainsub] - predict(rf.reg, data[trainsub,]))^2) #TRAIN MSE
rf.train.mse
spyvar.rf.pred = predict(rf.reg, data[-trainsub,]) # Predict with bagging
rf.test.mes = mean((data$spy_var[-trainsub] - spyvar.rf.pred)^2)
rf.reg$importance # MeanDecreaseGini is MDI
# MeanDecreaseAccuracy is MDA (based on bagging errors)
varImpPlot(rf.reg)
cat('RANDOM FOREST MODEL \n',
'Summary: \n',
strrep('-', 80),
#sapply(capture.output(summary(linmod)), function(x) paste(x, '\n')), '\n',
rf.reg,
strrep('-', 80), '\n',
'Train MSE: ', rf.train.mse, '\n',
'Test MSE: ', rf.test.mes, '\n')
cat('RANDOM FOREST MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(rf.reg), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', rf.train.mse, '\n',
'Test MSE: ', rf.test.mes, '\n')
rf.reg$importance # MeanDecreaseGini is MDI
cat('RANDOM FOREST MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(rf.reg), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Importance: \n',
strrep('-', 80),
rf.reg$importance,
strrep('-', 80), '\n',
'Train MSE: ', rf.train.mse, '\n',
'Test MSE: ', rf.test.mes, '\n')
cat('RANDOM FOREST MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(rf.reg), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Importance: \n',
strrep('-', 80),
sapply(capture.output(rf.reg$importance), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', rf.train.mse, '\n',
'Test MSE: ', rf.test.mes, '\n')
cat('RANDOM FOREST MODEL \n',
'Summary: \n',
strrep('-', 80),
sapply(capture.output(rf.reg), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Importance: \n',
strrep('-', 80), '\n',
#Gives both the number of variables at each split but also provides
#out-of-bag estimate of error rate
sapply(capture.output(rf.reg$importance), function(x) paste(x, '\n')), '\n',
strrep('-', 80), '\n',
'Train MSE: ', rf.train.mse, '\n',
'Test MSE: ', rf.test.mes, '\n')
View(data)
x_train = as.matrix(data[trainsub, -'spy_var'])
x_train = as.matrix(data[trainsub, -c('spy_var')])
x_train = as.matrix(data[trainsub])
x_train = as.matrix(data[,trainsub])
x_train = as.matrix(data[trainsub,])
x_train = as.matrix(data[trainsub, selevt = -c('spy_var')])
x_train = as.matrix(data[trainsub, select = -c('spy_var')])
x_train = as.matrix(subset(data[trainsub], select = -c('spy_var')))
x_train = as.matrix(subset(data[trainsub,], select = -c('spy_var')))
x_train = as.matrix(subset(data[trainsub,], select = -c(spy_var)))
View(x_train)
y_train = as.matrixdata[trainsub, "spy_var"]
y_train = as.matrix(data[trainsub, "spy_var"])
View(y_train)
View(x_train)
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = ) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = ) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
#Params
HIDDEN_SIZE <- 128
BATCH_SIZE <- 128
LAYERS <- 1
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = ) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
layer_dense(1, activation = 'relu')
View(x_train)
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
or(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
#Build Model
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
layer_dense(1, activation = 'relu')
#Build Model
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
model %>% layer_dense(1, activation = 'relu')
#Build Model
model <- keras_model_sequential()
library(keras)
#Build Model
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
#Build Model
model <- keras_model_sequential()
#Params
HIDDEN_SIZE <- 128
BATCH_SIZE <- 128
LAYERS <- 1
x_train = as.matrix(subset(data[trainsub,], select = -c(spy_var)))
y_train = as.matrix(data[trainsub, "spy_var"])
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS)
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
model %>% layer_dense(1, activation = 'relu')
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
}
model %>% layer_dense(1, activation = 'relu')
#Build Model
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
}
model %>% layer_dense(1, activation = 'relu')
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu') %>%
}
model %>% layer_dense(1, activation = 'relu')
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
LAYERS <- 2
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0]))) %>%
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
for(i in 1:LAYERS) cat (i)
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0])))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70,
validation_data = list(x_val, y_val)
)
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(1)#c(length(x_train[0])))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(1))#c(length(x_train[0])))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train[0] - 1)))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train)))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
odel %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(length(x_train)-1))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
###
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
View(x_train)
#Build Model
model <- keras_model_sequential()
model %>%
#layer_lstm(HIDDEN_SIZE, input_shape=c(MAXLEN, length(char_table))) %>%
layer_dense(HIDDEN_SIZE, activation = 'relu', input_shape = c(11))
for(i in 1:LAYERS){
model %>% layer_dense(HIDDEN_SIZE, activation = 'relu')
}
model %>% layer_dense(1, activation = 'relu')
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
###
model %>% fit(
x = x_train,
y = y_train,
batch_size = BATCH_SIZE,
epochs = 70
)
